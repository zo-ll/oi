{
  "models": [
    {
      "id": "qwen3-8b",
      "name": "Qwen3-8B",
      "repo": "MaziyarPanahi/Qwen3-8B-GGUF",
      "filename_template": "Qwen3-8B.{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "220,989 downloads, 8 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "meta-llama-3-1-8b",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "repo": "bartowski/Meta-Llama-3.1-8B-Instruct-GGUF",
      "filename_template": "Meta-Llama-3.1-8B-Instruct-{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "185,122 downloads, 313 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "mistral-7b-v0-3",
      "name": "Mistral-7B-Instruct-v0.3",
      "repo": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF",
      "filename_template": "Mistral-7B-Instruct-v0.3.{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "157,051 downloads, 131 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "llama-3-2-1b",
      "name": "Llama-3.2-1B-Instruct",
      "repo": "MaziyarPanahi/Llama-3.2-1B-Instruct-GGUF",
      "filename_template": "Llama-3.2-1B-Instruct.{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "148,113 downloads, 17 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "meta-llama-3-8b",
      "name": "Meta-Llama-3-8B-Instruct",
      "repo": "MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF",
      "filename_template": "Meta-Llama-3-8B-Instruct.{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "148,107 downloads, 101 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b",
      "name": "DeepSeek-R1-0528-Qwen3-8B",
      "repo": "MaziyarPanahi/DeepSeek-R1-0528-Qwen3-8B-GGUF",
      "filename_template": "DeepSeek-R1-0528-Qwen3-8B.{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "147,838 downloads, 7 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "gemma-3-1b-it",
      "name": "gemma-3-1b-it",
      "repo": "MaziyarPanahi/gemma-3-1b-it-GGUF",
      "filename_template": "gemma-3-1b-it.{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "146,115 downloads, 11 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "qwen2-5-7b",
      "name": "Qwen2.5-7B-Instruct",
      "repo": "MaziyarPanahi/Qwen2.5-7B-Instruct-GGUF",
      "filename_template": "Qwen2.5-7B-Instruct.{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "145,609 downloads, 11 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "llama-3-2-3b",
      "name": "Llama-3.2-3B-Instruct",
      "repo": "MaziyarPanahi/Llama-3.2-3B-Instruct-GGUF",
      "filename_template": "Llama-3.2-3B-Instruct.{quant}.gguf",
      "min_vram_gb": 2.3,
      "description": "144,778 downloads, 13 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "ministral-3-3b-reasoning-2512",
      "name": "Ministral-3-3B-Reasoning-2512",
      "repo": "MaziyarPanahi/Ministral-3-3B-Reasoning-2512-GGUF",
      "filename_template": "Ministral-3-3B-Reasoning-2512.{quant}.gguf",
      "min_vram_gb": 2.3,
      "description": "143,812 downloads, 4 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "llama-3-8b-32k-v0-1",
      "name": "Llama-3-8B-Instruct-32k-v0.1",
      "repo": "MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF",
      "filename_template": "Llama-3-8B-Instruct-32k-v0.1.{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "143,323 downloads, 58 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "wizardlm-2-7b",
      "name": "WizardLM-2-7B",
      "repo": "MaziyarPanahi/WizardLM-2-7B-GGUF",
      "filename_template": "WizardLM-2-7B.{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "142,534 downloads, 83 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "qwen2-7b",
      "name": "Qwen2-7B-Instruct",
      "repo": "MaziyarPanahi/Qwen2-7B-Instruct-GGUF",
      "filename_template": "Qwen2-7B-Instruct.{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "142,358 downloads, 11 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "mathstral-7b-v0-1",
      "name": "mathstral-7B-v0.1",
      "repo": "MaziyarPanahi/mathstral-7B-v0.1-GGUF",
      "filename_template": "mathstral-7B-v0.1.{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "142,106 downloads, 7 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "qwen2-5-3b",
      "name": "Qwen2.5-3B-Instruct",
      "repo": "Qwen/Qwen2.5-3B-Instruct-GGUF",
      "filename_template": "qwen2.5-3b-instruct-{quant}.gguf",
      "min_vram_gb": 2.3,
      "description": "65,051 downloads, 79 likes on HuggingFace",
      "tags": [
        "dynamic",
        "qwen"
      ]
    },
    {
      "id": "qwen2-5-coder-7b",
      "name": "Qwen2.5-Coder-7B-Instruct",
      "repo": "Qwen/Qwen2.5-Coder-7B-Instruct-GGUF",
      "filename_template": "qwen2.5-coder-7b-instruct-{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "44,584 downloads, 165 likes on HuggingFace",
      "tags": [
        "dynamic",
        "qwen"
      ]
    },
    {
      "id": "glm-4-7-flash-reap-23b-a3b",
      "name": "GLM-4.7-Flash-REAP-23B-A3B",
      "repo": "unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF",
      "filename_template": "GLM-4.7-Flash-REAP-23B-A3B-{quant}.gguf",
      "min_vram_gb": 14.3,
      "description": "35,248 downloads, 108 likes on HuggingFace",
      "tags": [
        "dynamic",
        "unsloth"
      ]
    },
    {
      "id": "llama-3-2-3b-uncensored",
      "name": "Llama-3.2-3B-Instruct-uncensored",
      "repo": "bartowski/Llama-3.2-3B-Instruct-uncensored-GGUF",
      "filename_template": "Llama-3.2-3B-Instruct-uncensored-{quant}.gguf",
      "min_vram_gb": 2.3,
      "description": "29,019 downloads, 81 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "deepseek-r1-distill-qwen-7b",
      "name": "DeepSeek-R1-Distill-Qwen-7B",
      "repo": "bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF",
      "filename_template": "DeepSeek-R1-Distill-Qwen-7B-{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "28,174 downloads, 104 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "deepseek-r1-distill-llama-8b",
      "name": "DeepSeek-R1-Distill-Llama-8B",
      "repo": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "filename_template": "DeepSeek-R1-Distill-Llama-8B-{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "25,238 downloads, 293 likes on HuggingFace",
      "tags": [
        "dynamic",
        "unsloth"
      ]
    },
    {
      "id": "qwen2-5-coder-3b",
      "name": "Qwen2.5-Coder-3B-Instruct",
      "repo": "Qwen/Qwen2.5-Coder-3B-Instruct-GGUF",
      "filename_template": "qwen2.5-coder-3b-instruct-{quant}.gguf",
      "min_vram_gb": 2.3,
      "description": "15,727 downloads, 52 likes on HuggingFace",
      "tags": [
        "dynamic",
        "qwen"
      ]
    },
    {
      "id": "goekdeniz-guelmez-josiefied-qwen3-8b-abliterated-v1",
      "name": "Goekdeniz-Guelmez_Josiefied-Qwen3-8B-abliterated-v1",
      "repo": "bartowski/Goekdeniz-Guelmez_Josiefied-Qwen3-8B-abliterated-v1-GGUF",
      "filename_template": "Goekdeniz-Guelmez_Josiefied-Qwen3-8B-abliterated-v1-{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "14,806 downloads, 29 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "l3-8b-stheno-v3-2",
      "name": "L3-8B-Stheno-v3.2",
      "repo": "bartowski/L3-8B-Stheno-v3.2-GGUF",
      "filename_template": "L3-8B-Stheno-v3.2-{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "12,391 downloads, 34 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "dolphin-2-9-4-llama3-1-8b",
      "name": "dolphin-2.9.4-llama3.1-8b",
      "repo": "bartowski/dolphin-2.9.4-llama3.1-8b-GGUF",
      "filename_template": "dolphin-2.9.4-llama3.1-8b-{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "12,359 downloads, 14 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "llama-3-1-8b",
      "name": "Llama-3.1-8B-Instruct",
      "repo": "unsloth/Llama-3.1-8B-Instruct-GGUF",
      "filename_template": "Llama-3.1-8B-Instruct-{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "12,194 downloads, 31 likes on HuggingFace",
      "tags": [
        "dynamic",
        "unsloth"
      ]
    },
    {
      "id": "qwen2-5-coder-7b-abliterated",
      "name": "Qwen2.5-Coder-7B-Instruct-abliterated",
      "repo": "bartowski/Qwen2.5-Coder-7B-Instruct-abliterated-GGUF",
      "filename_template": "Qwen2.5-Coder-7B-Instruct-abliterated-{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "6,698 downloads, 9 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "onellm-doey-chatqa-v1-llama-3-2-1b",
      "name": "OneLLM-Doey-ChatQA-V1-Llama-3.2-1B",
      "repo": "bartowski/OneLLM-Doey-ChatQA-V1-Llama-3.2-1B-GGUF",
      "filename_template": "OneLLM-Doey-ChatQA-V1-Llama-3.2-1B-{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "4,375 downloads, 0 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "apertus-8b-2509",
      "name": "Apertus-8B-Instruct-2509",
      "repo": "unsloth/Apertus-8B-Instruct-2509-GGUF",
      "filename_template": "Apertus-8B-Instruct-2509-{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "2,886 downloads, 16 likes on HuggingFace",
      "tags": [
        "dynamic",
        "unsloth"
      ]
    },
    {
      "id": "qwen1-5-7b-chat",
      "name": "Qwen1.5-7B-Chat",
      "repo": "Qwen/Qwen1.5-7B-Chat-GGUF",
      "filename_template": "qwen1_5-7b-chat-{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "2,698 downloads, 70 likes on HuggingFace",
      "tags": [
        "dynamic",
        "qwen"
      ]
    },
    {
      "id": "google-gemma-3-1b-it",
      "name": "google_gemma-3-1b-it",
      "repo": "bartowski/google_gemma-3-1b-it-GGUF",
      "filename_template": "google_gemma-3-1b-it-{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "2,651 downloads, 14 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "amd-olmo-1b-sft-dpo",
      "name": "AMD-OLMo-1B-SFT-DPO",
      "repo": "bartowski/AMD-OLMo-1B-SFT-DPO-GGUF",
      "filename_template": "AMD-OLMo-1B-SFT-DPO-{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "2,468 downloads, 4 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "sailor2-1b-chat",
      "name": "Sailor2-1B-Chat",
      "repo": "bartowski/Sailor2-1B-Chat-GGUF",
      "filename_template": "Sailor2-1B-Chat-{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "2,346 downloads, 2 likes on HuggingFace",
      "tags": [
        "dynamic",
        "bartowski"
      ]
    },
    {
      "id": "lfm2-8b-a1b",
      "name": "LFM2-8B-A1B",
      "repo": "unsloth/LFM2-8B-A1B-GGUF",
      "filename_template": "LFM2-8B-A1B-{quant}.gguf",
      "min_vram_gb": 5.3,
      "description": "1,972 downloads, 43 likes on HuggingFace",
      "tags": [
        "dynamic",
        "unsloth"
      ]
    },
    {
      "id": "gemma-3-1b-it-qat-q4-0",
      "name": "gemma-3-1b-it-qat-q4_0",
      "repo": "google/gemma-3-1b-it-qat-q4_0-gguf",
      "filename_template": "gemma-3-1b-it-{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "1,219 downloads, 114 likes on HuggingFace",
      "tags": [
        "dynamic",
        "google"
      ]
    },
    {
      "id": "codeqwen1-5-7b-chat",
      "name": "CodeQwen1.5-7B-Chat",
      "repo": "Qwen/CodeQwen1.5-7B-Chat-GGUF",
      "filename_template": "codeqwen-1_5-7b-chat-{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "757 downloads, 109 likes on HuggingFace",
      "tags": [
        "dynamic",
        "qwen"
      ]
    },
    {
      "id": "llama-3-2-3b-abliterated",
      "name": "Llama-3.2-3B-Instruct-abliterated",
      "repo": "MaziyarPanahi/Llama-3.2-3B-Instruct-abliterated-GGUF",
      "filename_template": "Llama-3.2-3B-Instruct-abliterated.{quant}.gguf",
      "min_vram_gb": 2.3,
      "description": "476 downloads, 2 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "olmo-2-0425-1b",
      "name": "OLMo-2-0425-1B-Instruct",
      "repo": "unsloth/OLMo-2-0425-1B-Instruct-GGUF",
      "filename_template": "OLMo-2-0425-1B-Instruct-{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "360 downloads, 7 likes on HuggingFace",
      "tags": [
        "dynamic",
        "unsloth"
      ]
    },
    {
      "id": "gemma-3-1b-it-abliterated",
      "name": "gemma-3-1b-it-abliterated",
      "repo": "MaziyarPanahi/gemma-3-1b-it-abliterated-GGUF",
      "filename_template": "gemma-3-1b-it-abliterated.{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "272 downloads, 0 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "gemma-3-1b-thinking-v2",
      "name": "gemma-3-1b-thinking-v2",
      "repo": "MaziyarPanahi/gemma-3-1b-thinking-v2-GGUF",
      "filename_template": "gemma-3-1b-thinking-v2.{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "210 downloads, 1 likes on HuggingFace",
      "tags": [
        "dynamic",
        "maziyarpanahi"
      ]
    },
    {
      "id": "codegemma-7b-it",
      "name": "codegemma-7b-it",
      "repo": "google/codegemma-7b-it-GGUF",
      "filename_template": "codegemma-7b-it-f16.gguf",
      "min_vram_gb": 4.7,
      "description": "100 downloads, 61 likes on HuggingFace",
      "tags": [
        "dynamic",
        "google"
      ]
    },
    {
      "id": "gemma-3-1b-pt-qat-q4-0",
      "name": "gemma-3-1b-pt-qat-q4_0",
      "repo": "google/gemma-3-1b-pt-qat-q4_0-gguf",
      "filename_template": "gemma-3-1b-pt-{quant}.gguf",
      "min_vram_gb": 1.1,
      "description": "86 downloads, 12 likes on HuggingFace",
      "tags": [
        "dynamic",
        "google"
      ]
    },
    {
      "id": "codegemma-7b",
      "name": "codegemma-7b",
      "repo": "google/codegemma-7b-GGUF",
      "filename_template": "codegemma-7b-f16.gguf",
      "min_vram_gb": 4.7,
      "description": "53 downloads, 25 likes on HuggingFace",
      "tags": [
        "dynamic",
        "google"
      ]
    },
    {
      "id": "codegemma-1-1-7b-it",
      "name": "codegemma-1.1-7b-it",
      "repo": "google/codegemma-1.1-7b-it-GGUF",
      "filename_template": "codegemma-1.1-7b-it-f16.gguf",
      "min_vram_gb": 4.7,
      "description": "8 downloads, 13 likes on HuggingFace",
      "tags": [
        "dynamic",
        "google"
      ]
    }
  ]
}