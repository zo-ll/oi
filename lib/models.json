{
  "models": [
    {
      "id": "qwen3-8b",
      "name": "Qwen3 8B",
      "repo": "Qwen/Qwen3-8B-GGUF",
      "filename_template": "qwen3-8b-{quant}.gguf",
      "min_vram_gb": 5.0,
      "description": "General/reasoning/math with thinking mode",
      "tags": ["general", "reasoning", "math"]
    },
    {
      "id": "qwen2.5-coder-7b",
      "name": "Qwen2.5 Coder 7B Instruct",
      "repo": "Qwen/Qwen2.5-Coder-7B-Instruct-GGUF",
      "filename_template": "qwen2.5-coder-7b-instruct-{quant}.gguf",
      "min_vram_gb": 4.7,
      "description": "Coding specialist",
      "tags": ["coding", "specialist"]
    },
    {
      "id": "ministral-3-8b",
      "name": "Ministral 3 8B Instruct 2512",
      "repo": "unsloth/Ministral-3-8B-Instruct-2512-GGUF",
      "filename_template": "Ministral-3-8B-Instruct-2512-{quant}.gguf",
      "min_vram_gb": 5.2,
      "description": "Latest Mistral, general use",
      "tags": ["general", "mistral"]
    },
    {
      "id": "deepseek-r1-distill-llama-8b",
      "name": "DeepSeek R1 Distill Llama 8B",
      "repo": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
      "filename_template": "DeepSeek-R1-Distill-Llama-8B-{quant}.gguf",
      "min_vram_gb": 4.9,
      "description": "Reasoning/chain-of-thought",
      "tags": ["reasoning", "chain-of-thought"]
    },
    {
      "id": "gemma-2-2b",
      "name": "Gemma 2 2B Instruct",
      "repo": "bartowski/gemma-2-2b-it-GGUF",
      "filename_template": "gemma-2-2b-it-{quant}.gguf",
      "min_vram_gb": 1.5,
      "description": "Lightweight/fast for quick tasks",
      "tags": ["lightweight", "fast", "google"]
    },
    {
      "id": "phi-3-mini",
      "name": "Phi-3 Mini 4K Instruct",
      "repo": "microsoft/Phi-3-mini-4k-instruct-gguf",
      "filename_template": "Phi-3-mini-4k-instruct.Q4_K_M.gguf",
      "min_vram_gb": 2.3,
      "description": "Efficient small model (only Q4 available)",
      "tags": ["efficient", "microsoft"],
      "default_quant": "Q4_K_M"
    },
    {
      "id": "qwen2-math-7b",
      "name": "Qwen2 Math 7B",
      "repo": "QuantFactory/Qwen2-Math-7B-GGUF",
      "filename_template": "Qwen2-Math-7B.{quant}.gguf",
      "min_vram_gb": 4.5,
      "description": "Math specialist",
      "tags": ["math", "specialist"]
    }
  ],
  "quantizations": {
    "Q2_K": {"description": "Smallest, fastest, lowest quality"},
    "Q3_K_S": {"description": "Small and fast, decent quality"},
    "Q3_K_M": {"description": "Balanced 3-bit quantization"},
    "Q3_K_L": {"description": "Higher quality 3-bit"},
    "Q4_0": {"description": "Legacy 4-bit format"},
    "Q4_K_S": {"description": "Small 4-bit, good speed"},
    "Q4_K_M": {"description": "Recommended default, balanced quality/size"},
    "Q4_K_L": {"description": "High quality 4-bit"},
    "Q5_K_S": {"description": "Higher quality, larger size"},
    "Q5_K_M": {"description": "Near-lossless quality"},
    "Q6_K": {"description": "Very high quality"},
    "Q8_0": {"description": "Best quality, largest 8-bit"}
  }
}
